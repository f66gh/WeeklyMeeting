# 2025.6.17 例会

## 师兄给的方向

**并行处理云化**

基于端云一体化架构，将计算服务容器化部署到容器集群，通过任务分片和分布式队列等形式实现并行处理。建立智能调度机制，根据负载情况动态分配云端资源，通过水平扩展和资源池化技术实现云版处理能力达到单机版3倍以上。

任务：科学计算和物理仿真

具备以下任务特性

* 任务易于拆分   
* 任务同质化+数据异质化        
* 计算密集型       
* 任务依赖关系明确       
* 延迟不敏感        
* 吞吐量优先        
* 允许排队       
* 有状态/中间结果重要       
* 高精度要求       
* 高频率数据交换       
*  资源需求可预测        
* 硬件加速支持

**场景总结**

延迟非敏感的计算密集型任务，不会和边缘计算有关；最终通过【专用】集群承载 类似的其它任务：

* XR场景/模型预渲染任务
* AI训练
* 延迟非敏感的推理（大模型）

**可选决策内容**

Case 1（负载均衡+资源调度）: 多种通用的Worker微服务承担异构任务（实际上直接简化成Serverless可能更靠谱），于是Worker间会有的中间数据传输问题 

Case 2（服务放置+资源调度）：将大任务按照任务分配，设置若干专用的Worker，按照{系统剩余资源，预期资源}等手段，动态对Worker进行调度

**考虑的因素**（目标/约束）

* 专用集群的运营成本 
* 吞吐量
* 等待时间

## 老师建议

优化目标可以是冷门一点的（比如安全性、稳定性，我觉得最小化最大等待时间这种也可以考虑）



## 调研（只能读摘要）

云端并行化不完善，以及受到移动端通信问题的影响，开发出**节能**的资源管理算法

* Energy-Efficient Real-Time Job Mapping and Resource Management in Mobile-Edge Computing **移动边缘计算中的节能实时任务映射和资源管理**

* 移动边缘计算（MEC）已成为一种使物联网（IoT）设备能够处理计算密集型任务的理想范式。由于服务器上任务处理算法的并行化不完善以及物联网设备移动性对无线网络中数据通信质量的影响，在任务调度过程中联合考虑服务器资源分配和物联网设备移动性对于充分利用 MEC 至关重要，而这一点在现有研究中往往被忽视。通过联合考虑任务调度、服务器资源分配和物联网设备移动性，我们研究了具有通信和计算争用的 MEC 中带有时限约束的任务卸载和资源管理问题，旨在最大化物联网设备的总节能效果。对于问题离线版本，其中任务信息是预先已知的，我们将其建模为整数线性规划问题，并提出了一种具有常数性能保证的近似算法 LHJS。对于在线版本，其中任务信息仅在发布时已知，我们提出了一种启发式算法 LBS，该算法在每次任务发布时被调用。 最后，我们使用来自实际应用的参数进行实验，以评估其性能。

在云端协同实现节能的前提下，必须保护边缘网络用户的精确位置信息（好6的角度）

* GEES: Enabling Location Privacy-Preserving Energy Saving in Multi-Access Edge Computing  **GEES：在多接入边缘计算中实现位置隐私保护节能**
* 全球 5G 网络的部署导致边缘服务器数量大幅增加，以支持边缘网络用户日益增长的低服务延迟需求。然而，全天候运行边缘服务器会导致巨大的能源消耗和过度的碳排放。在新多接入边缘计算（MEC）架构中，实现节能的边缘资源提供是达成可持续发展目标的关键。近期，已有多种方法被提出以解决云计算和 MEC 中的节能需求响应问题。然而，必须始终提供边缘网络用户的精确位置信息，这会牺牲用户隐私。为在 MEC 中节能的同时保护边缘网络用户的地理位置隐私，我们系统地提出了这一位置隐私保护边缘需求响应（LEDR）问题。为高效且有效地解决 LEDR 问题，我们通过结合差分地理模糊化技术，在保护用户隐私的同时，通过理论分析进行推断，以最大化系统效用和能源效率，提出了名为 GEES 的系统。 基于综合真实世界数据集进行了广泛而全面的实验，结果表明，在能效、用户隐私和系统效用方面，GEES 平均比代表性方法高出 23.02%、31.47%和 17.29%。

现有微服务架构自动扩展器不适用于资源受限的环境，并且Pod的固有延迟加剧问题。所以提出了一种自动扩展器促进微服务之间的资源交换，并提出了Pod启动和终止带来的延迟。

* Towards resource-efficient reactive and proactive auto-scaling for microservice architectures **面向微服务架构的资源高效反应式和主动式自动伸缩**

* 微服务架构在学术界和工业界都日益普及，为软件开发和部署提供了更高的敏捷性、弹性和可维护性。为了简化微服务架构的扩展操作，像 Kubernetes 这样的容器编排平台配备了水平 Pod 自动扩展器（HPAs），用于调整微服务的资源以适应波动的负载。然而，现有的 HPAs 不适用于资源受限的环境，因为它们基于微服务的单个资源容量做出扩展决策，导致服务不可用、资源管理不当和财务损失。此外，初始化和终止微服务 Pod 的固有延迟阻碍了 HPAs 及时响应负载波动，进一步加剧了这些问题。为了解决这些问题，我们分别提出了 Smart HPA 和 ProSmart HPA，即反应式和主动式的资源高效水平 Pod 自动扩展器。Smart HPA 采用反应式扩展策略，促进微服务之间的资源交换，优化资源受限环境下的自动扩展。 对于 ProSmart HPA，我们开发了一种基于机器学习的资源高效扩展策略，该策略主动管理资源需求，以解决微服务 Pod 启动和终止引起的延迟，同时在资源受限的环境中实现预占式资源共享。我们的实验结果表明，Smart HPA 的表现优于 Kubernetes 基准 HPA，而 ProSmart HPA 通过减少资源过度使用、过度配置和配置不足，并将更多资源分配给微服务应用，超越了 Smart HPA 和 Kubernetes HPA。

在保证微服务架构的安全同时提升了工作流的性能，设计了一种针对基于微服务的应用程序的安全调度模型。

* **基于 D3QN 的云环境中微服务工作流安全调度** D3QN-based secure scheduling of microservice workflows in cloud environments

* 近年来，由于其松散耦合的特性，微服务架构被广泛应用于软件设计，包括云中的科学工作流调度。随着容器技术的发展，其快速启动和低开销使其成为微服务的首选部署技术。然而，当前微服务架构的一个关键问题是暴露私有和敏感数据的风险。现有工作研究了并探索了微服务的新架构，但隐私和时间之间的权衡仍未得到充分考虑。为了填补这一空白，我们首先设计了一个考虑用户和云提供者安全级别的安全模型，并提出了一种满足预算约束和任务隐私要求的工怍流调度算法。我们将安全调度问题转化为马尔可夫决策过程（MDP），并提出了基于双斗篷深度 Q 网络（D3QN）的微服务工作流调度算法（D3MWS），该算法不仅能在预算约束下最小化完成时间，还能满足工作流任务的安全要求。 最后，选择了云计算中著名的 workflow 应用程序进行实验。实验结果表明，所提出的算法在满足微服务的安全要求的同时，与其他算法相比，在不同任务数量下将每个 workflow 的平均任务完成时间减少了 10.91%。

用广泛的分类法涵盖工业中大规模微服务项目中常见的故障。、

* A Taxonomy of Integration-Relevant Faults for Microservice Testing **面向微服务测试的集成相关故障分类法**

* 微服务已成为一种流行的架构范式，为软件开发提供了一种灵活且可扩展的方法。然而，它们的分布式特性和多样化的技术栈引入了固有的复杂性，超越了单体系统的复杂性。微服务的集成面临着诸多挑战，从通信故障到兼容性问题，都会影响系统的可靠性。了解这些分布式组件中的故障对于防止缺陷、制定测试策略和实施鲁棒性测试至关重要。尽管这些软件系统具有重要意义，但现有的分类法有限，因为它们主要关注非功能性属性或缺乏实证验证。为了解决这些差距，本文提出了一个广泛的分类法，涵盖了工业中大规模微服务系统中最常见的集成相关故障。通过系统文献综述和与行业专家进行的十次半结构化访谈，我们识别了真实世界微服务项目中常见的集成相关故障。 我们的最终分类法通过一项调查得到验证，该调查邀请了另外16位从业者参与，确认几乎所有故障类别（21/23）都至少被50%的受访者遇到过。

用大语言模型自动生成微服务开发的系统，使开发者能够专注于更高级的的设计和集成任务。

* LLM-Generated Microservice Implementations from RESTful API Definitions **从 RESTful API 定义生成 LLM 微服务实现**
* 对可扩展、可维护和快速部署系统的需求日益增长，使得微服务架构在软件开发中变得广泛流行。本文介绍了一个使用大型语言模型（LLMs）自动进行 API 优先的 RESTful 微服务开发的系统。该系统协助创建 OpenAPI 规范，根据规范生成服务器代码，并通过分析执行日志和错误消息的反馈循环来优化代码。通过专注于 API 优先的方法，该系统确保微服务具有明确定义的接口，从而在整个开发生命周期中促进一致性和可靠性。日志分析的集成使 LLM 能够高效地检测和解决问题，减少生成功能完善且健壮服务所需的迭代次数。该过程自动化了微服务的生成，并简化了调试和优化阶段，使开发者能够专注于更高级的设计和集成任务。该系统有可能使软件开发者、架构师和组织受益，以加快软件开发周期并减少人工工作量。 为了评估该系统的潜力，我们与六位行业从业者进行了调查。在调查从业者后，该系统在提升开发速度、自动化重复任务以及简化原型设计流程方面表现出显著优势。虽然经验丰富的开发者对其在特定任务上的效率表示赞赏，但有些人对其在处理高级定制和大型项目方面的局限性表示担忧。